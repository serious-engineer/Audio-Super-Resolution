# AudioSR-GAN: Speech Bandwidth Extension (8 kHz â†’ 22.05 kHz)

## ğŸ“˜ Overview

This project performs **Audio Superâ€‘Resolution (Speech Bandwidth Extension)**, transforming **8 kHz narrowâ€‘band audio** into **22.05 kHz wideâ€‘band audio** using:

* A **CNNâ€‘based generator** (SRResNetâ€‘style)
* A **PatchGAN discriminator** for realism
* **Melâ€‘spectrogram domain training**
* **neural vocoders** (Vocos) for waveform reconstruction

---

## ğŸ”„ Full Workflow (Highâ€‘Level)

```
  Lowâ€‘Resolution Audio (8 kHz)
            â”‚
            â–¼
     Upsample to 22.05 kHz
            â”‚
            â–¼
   Convert to Logâ€‘Mel Spectrogram
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   CNN / SRResNet Generator   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   Predicted Highâ€‘Resolution Mel
            â”‚
            â–¼
   Neural Vocoder (HiFiâ€‘GAN/Vocos)
            â”‚
            â–¼
  Final Reconstructed 22.05 kHz Audio
```
# Mel configuration used across training, inference, and vocoder reconstruction
```
Sample rate: 22,050 Hz (fixed requirement â€” mel extractor MUST match vocoder SR)

n_mels: 80 (required by vocos-mel-22kHz)

n_fft: 1024 (internally forced)

Hop length: 256 (internally forced)

Window length: 1024 (internally forced)

Padding mode: 'same' (ensures correct temporal alignment)

Mel scale: HTK mel scale (default in extractor)

Log mel: apply_log = False â†’ linear mel, because Vocos expects linear mel inputs

âœ” Why these configs matter

80 mel bins are standard for speech models and required for the Vocos vocoder you use.

apply_log = False prevents incompatibility with vocosâ€‘melâ€‘22kHz (which internally applies its own log processing).

Fixing n_fft = 1024 and hop = 256 gives a 12 ms hop, a sweet spot between temporal detail and GAN stability.

This consistent mel configuration ensures:

Stable generator training

Proper alignment between LR/HR mel pairs

Correct conditioning for both HiFiâ€‘GAN and Vocos vocoders strike a balance between timeâ€“frequency resolution, GAN stability, and compatibility with HiFiâ€‘GAN/Vocos vocoders. The hop length of 256 ensures smooth reconstruction and avoids phase artifacts after vocoder synthesis. The 128â€‘mel dimension provides enough resolution for high-frequency detail without making training unstable or memory-heavy.
```
---

## ğŸ“ 1. Dataset Preparation (8 kHz â†’ 22.05 kHz)

### **Generate HR (22,050 Hz) & LR (8,000 Hz) pairs**

```bash
python -m  src.dataset.make_low_sr_dataset --in_root archive
```
#### **Check Bandwidth of dataset**
```
python -m  src.dataset.check_bw --input data/hr/p225_001.wav 
python -m  src.dataset.audio_properties data/hr/p225_001.wav 
```
---

## ğŸ§  2. Train the CNN Baseline Model (Or the CNN-GAN model in Step 3 )

```bash
python -m src.train --dataset_dir data --out_dir checkpoints --batch_size 32 --epochs 100
```

---

## ğŸ›ï¸ 3. Train the GAN Model

```bash
python -m src.train_gan --dataset_dir data --out_dir checkpoints_gan --batch_size 32 --epochs 100
```

---

## ğŸ”Š 4. Standard Inference (Generator Only)

### **A. Run inference on entire HR directory**

```bash
python -m src.infer --generator_ckpt checkpoints_gan/generator_final.pt --output_dir outputs_gan
```

### **B. Limit inference to N files**

```bash
python -m src.infer --generator_ckpt checkpoints_gan/generator_final.pt --max_files 20 --output_dir outputs_gan
```

### **C. Inference on a single LR file**

```bash
python -m src.infer --input_wav data/low_sr/p225_001.wav --generator_ckpt checkpoints/generator_final.pt --hr_dir data/hr --output_dir outputs_gan
```

---

## ğŸ”¥ 5. Inference (Using Griffin Lim Vocoder)**

```bash
python -m src.infer --input_wav data/low_sr/p225_001.wav --generator_ckpt checkpoints/generator_final.pt --hr_dir data/hr --output_dir outputs --vocoder griffin
```

---

## ğŸ§ª 6. Quick Testing Utilities

```bash
python -m src.infer --input_wav data/low_sr/p225_001.wav
python -m src.infer --max_files 5
```

---

## ğŸ“ˆ 7. Evaluation

### **Evaluate SR quality (STOI, PESQ, LSD, SNR, MSE)**

```bash
python -m src.utils.eval --sr_file outputs_gan/p225_001_sr.wav
```

### **Evaluate Vocoder Reconstructions to Test Vocoder Quality**

```bash
python -m src.utils.vocoder_eval --hr_dir data/test/ --max_files 5 --save_recon
```

---

## ğŸ§© Block Diagram (Melâ€‘Domain GAN)

```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                 Lowâ€‘SR Mel (Input)            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   SRResNet Generator (G)     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
           Predicted Highâ€‘Resolution Mel
                        â”‚
                        â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ PatchGAN Discriminator (D) â€“ optional GAN  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 Adversarial Loss
```

---

## ğŸ¯ Future Improvements

* Diffusionâ€‘based vocoders
* Multiâ€‘speaker embeddings
* Perceptual losses (wav2vec2 / Encodec)
* Largeâ€‘scale dataset training (VCTK, LibriSpeech)
